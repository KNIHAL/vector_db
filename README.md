# ğŸ§  Vector DB â€” Local Vector Database with CLI & API (Python)

A **production-style, local-first Vector Database built from scratch in pure Python**, with **CLI and FastAPI wrappers**, designed for **semantic search, document ingestion, and RAG pipelines** â€” without paid APIs, cloud services, or heavy frameworks.

This project focuses on **fundamentals, explainability, and real-world usability**, making it suitable for:
- RAG backends
- GenAI / Backend portfolios
- System design & interview discussions

---

## ğŸš€ Why This Project Exists

Most vector databases abstract away the internals behind black-box tooling.  
This project was built to answer one core question:

> **â€œHow does a vector database actually work under the hood?â€**

By implementing everything from scratch, this project demonstrates:
- How documents are converted into vectors
- How similarity search works using cosine similarity
- How embeddings evolve dynamically with new data
- How document ingestion (PDF / MD / TXT) works in practice
- How a vector database plugs directly into RAG systems

---

## ğŸ¯ Project Goals

- Build a **real vector database engine**, not a wrapper
- Keep everything **local, free, and framework-light**
- Maintain **clean separation of concerns**
- Support **document ingestion (not just toy text input)**
- Be **RAG-ready out of the box**
- Stay **interview-explainable**

---

## ğŸ§± High-Level Architecture

```text
CLI / API / RAG System
â†“
Ingestion Layer
(PDF / MD / TXT â†’ Chunks)
â†“
Vector DB Engine
(TF-IDF + Similarity)
â†“
vectors.json
```


---

## ğŸ“‚ Project Structure

```yaml
vector_db/
â”‚
â”œâ”€â”€ core/
â”‚ â”œâ”€â”€ storage.py # Disk persistence (JSON)
â”‚ â”œâ”€â”€ tfidf.py # TF-IDF embedding engine
â”‚ â”œâ”€â”€ vectordb.py # Vector DB core logic
â”‚ â”œâ”€â”€ loaders.py # PDF / MD / TXT loaders
â”‚ â””â”€â”€ chunker.py # Text chunking logic
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ vectors.json # Stored vectors
â”‚ â””â”€â”€ uploads/ # Optional persisted source files
â”‚
â”œâ”€â”€ cli.py # CLI interface
â”œâ”€â”€ api.py # FastAPI wrapper
â””â”€â”€ README.md
```


---

## ğŸ§© Core Components

### 1ï¸âƒ£ Vector DB Engine (`vectordb.py`)
- Inserts text + metadata
- Converts text â†’ TF-IDF vectors
- Performs cosine similarity search
- Supports delete operations
- Automatically adapts when new data is added

**Role:** Retriever (RAG terminology)

---

### 2ï¸âƒ£ Embedding Layer (`tfidf.py`)
- Pure-Python TF-IDF implementation
- Corpus-aware embeddings
- Re-fits dynamically on ingestion

**Why TF-IDF?**
- Fully local
- Explainable
- Lightweight
- Strong baseline before neural embeddings

---

### 3ï¸âƒ£ Storage Layer (`storage.py`)
- JSON-based persistence
- Human-readable & debuggable
- No hidden magic

---

### 4ï¸âƒ£ Ingestion Layer (`loaders.py`, `chunker.py`)
- Supports **PDF, Markdown, and Text files**
- Extracts text
- Splits into overlapping chunks
- Each chunk stored as an independent vector

This is what makes the project **non-toy** and production-relevant.

---

### 5ï¸âƒ£ API Layer (`api.py`)
- FastAPI-based wrapper
- Input validation & proper status codes
- File ingestion endpoint
- Swagger UI for testing

---

## âœ… Features

### Vector DB Core
- Text â†’ Vector (TF-IDF)
- Cosine similarity search
- Top-K retrieval
- Metadata support
- Persistent storage

### CLI
- Insert text
- Search vectors
- Delete by ID
- Ingest PDF / MD / TXT files
- Optional file persistence (`data/uploads/`)

### API
- `POST /insert` â†’ insert raw text
- `POST /search` â†’ semantic search
- `POST /ingest-file` â†’ document ingestion
- `DELETE /delete` â†’ remove vector
- `GET /health` â†’ health check

---

## âŒ Intentionally Not Included

To keep the system focused and explainable:

- No SQL
- No joins or schemas
- No cloud services
- No paid APIs
- No neural embeddings (yet)
- No LLM generation logic

> **This project is the Retriever, not the Generator.**

---

## â–¶ï¸ How to Run (WSL / Linux)

```bash
python3 -m venv env
source env/bin/activate
pip requirements.txt
uvicorn api:app --reload
```
Swagger UI:

```text
http://127.0.0.1:8000/docs
```

### ğŸ§ª Testing

**CLI**

```text
python cli.py
```

- Ingest PDF / MD / TXT using local paths
- Search content semantically
- Verify chunk metadata

**API**

- Test /ingest-file via Swagger
- Search ingested documents
- Restart server â†’ data persists


## ğŸ”Œ How This Is Used in RAG

This Vector DB plugs directly into a RAG pipeline:

1ï¸âƒ£ Ingestion

- Chunk documents
- Store via CLI or /ingest-file

2ï¸âƒ£ Retrieval

- User query â†’ /search
- Top-K relevant chunks returned

3ï¸âƒ£ Generation (External)

- Retrieved chunks passed to an LLM
- Answer generated outside this system

**Flow:**

```text
User Query â†’ Vector DB â†’ Context â†’ LLM â†’ Answer

```
ğŸ‘‰ No changes required in this DB to support RAG.

## ğŸ§  Key Learnings

- Vector databases are about math + similarity, not tables
- Document ingestion is essential for real RAG systems
- Chunking is as important as embeddings
- Clean separation of engine, CLI, and API matters
- TF-IDF is a strong, explainable foundation


## Status: FROZEN (v1.0)
 ğŸ”œ Future (Optional, Not Required)
- Neural embeddings
- Scraper-based ingestion
- Full RAG demo

## ğŸ“„ License

MIT â€” free to use, learn, and extend.
